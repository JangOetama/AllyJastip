name: Scrape and Update jastip.json

on:
  schedule:
    - cron: "0 0 * * *" # Jalankan setiap hari pada tengah malam (UTC)
  workflow_dispatch: # Izinkan manual trigger

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: Scrape website and generate jastip.json
        id: scrape
        run: |
          import requests
          from bs4 import BeautifulSoup
          import json

          # Login credentials
          login_url = "https://feelbuyshop.com/preorderjastip/?f=login"
          home_url = "https://feelbuyshop.com/preorderjastip/?f=home"
          payload = {
              "username": "085161117349",
              "submit": ""
          }

          # Start session and login
          session = requests.Session()
          response = session.post(login_url, data=payload)

          if response.status_code == 200:
              print("Login successful")
          else:
              raise Exception("Login failed")

          # Scrape the home page
          response = session.get(home_url)
          soup = BeautifulSoup(response.text, 'html.parser')

          products = []
          for item in soup.select("#mydivproduct .product__item"):
              product_data = {}

              # Get image URL
              img_tag = item.select_one(".product__item__pic.set-bg")
              if img_tag and "data-setbg" in img_tag.attrs:
                  product_data["image_url"] = img_tag["data-setbg"]
              else:
                  product_data["image_url"] = None

              # Get product name
              name_tag = item.select_one(".product__item__text h6")
              product_data["name"] = name_tag.text.strip() if name_tag else None

              # Get prices
              price_tag = item.select_one(".product__item__text h5")
              if price_tag:
                  prices = price_tag.text.strip().split("\n")
                  original_price = prices[1].replace("Rp.", "").replace(",", "").strip()
                  discounted_price = prices[2].replace("Rp.", "").replace(",", "").strip()
                  discount_percentage = prices[3].replace("<sup><font color=\"red\">", "").replace("</font></sup>", "").strip()

                  product_data["original_price"] = int(original_price) if original_price.isdigit() else None
                  product_data["discounted_price"] = int(discounted_price) if discounted_price.isdigit() else None
                  product_data["discount_percentage"] = discount_percentage
              else:
                  product_data["original_price"] = None
                  product_data["discounted_price"] = None
                  product_data["discount_percentage"] = None

              products.append(product_data)

          # Save to jastip.json
          with open("jastip.json", "w", encoding="utf-8") as f:
              json.dump(products, f, ensure_ascii=False, indent=4)

          print("Scraping completed and jastip.json updated")

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add jastip.json
          git commit -m "Update jastip.json with latest scraped data"
          git push https://${{ secrets.GH_TOKEN }}@github.com/${{ github.repository }}.git HEAD:main
